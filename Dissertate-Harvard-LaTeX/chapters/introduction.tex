%!TEX root = ../dissertation.tex
\chapter{Introduction}
\label{introduction}

La predicción y clasificación supervisada de datos numéricos siempre ha sido un tema central de interés científico en el área de ciencia de datos y aprendizaje automático. También hay numerosas investigaciones publicadas en torno a el preprocesamiento de datos. Sin embargo, hasta hace unos años apenas se había prestado interés a la clasificación de datos ordinales, también conocida como regresión ordinal.

\section{El problema de la clasificación ordinal}
Los datos de naturalieza ordinal no son más que datos cuyas clases muestran un claro orden. Es decir, para cada instancia $x \in X \subseteq \Re^K $, con clase $y\in Y={C_1,C_2,...,C_n}$, se tiene una relación de orden sobre las clases tal que $C_1 \prec C_2 \prec ... \prec C_n$. Por ejemplo, datos recogidos de encuestas con diferentes grados de valoración, datos de resultados médicos considerando diferentes enfermedades, datos de psicología o, en general, datos obtenidos en cualquier área científica donde los humanos intervengan para la generación de datos. \newline
Por tanto, el problema de la clasificación de datos ordinales, o regresión ordinal, trata de clasificar datos ordinales considerando en los algoritmos el orden que presentan entre sí las clases de los datos, para obtener una clasificación más fiel a la naturaleza intrínseca de estos datos, y por tanto, construir un modelo más preciso. Pongamos como ejemplo datos obtenidos de una encuesta de valoración de un servicio que realizan un número de clientes, donde las posibles etiquetas son: \textit{$\left[malo, normal, bueno, muy\ bueno, excelente\right]$}. En este caso, las clases contienen información de orden, pues pertenecer a la clase \textit{malo} implica una peor valoración que pertenecer a la clase \textit{excelente}, y por tanto un algoritmo de clasificación diseñado para tratar con datos ordinales debería considerar diferentes costes según el tipo de errores de clasificación que se produjesen. Por ejemplo, debería de penalizar más el clasificar como \textit{malo} un servicio \textit{excelente} que clasificarlo como \textit{muy bueno}. Otro ejemplo similar de regresión ordinal sería la clasificación del riesgo de varias enfermedades en \textit{$\left[bajo, moderado, severo\right]$} en base a los síntomas presentados por los pacientes. En este caso, la relación de orden presente sería los niveles de gravedad de una enfermedad. \newline
Los problemas de clasificación de datos ordinales han estado presentes desde hace mucho, sin embargo se han abordado mayoritariamente como problemas nominales estándar, sin tener en cuenta el orden presente entre clases que las hace comparables, y por tanto llegando a soluciones no óptimas, aunque en trabajos como \cite{Gutiérrez2016} se demostró que el uso de técnicas específicamente diseñadas para este tipo de problemas da mejores resultados que simplemente aplicar las técnicas estándar para datos nominales. 

\subsection{Ranking, ordenación y ranking multipartito}
A pesar de su parecido, existen diferencias entre las técnicas de regresión ordinal y las de ránking, ordenación o ránking multipartito. En concreto, dado un conjunto de datos con etiquetas ordenadas, el objetivo del ránking será aprender un orden parcial subyacente en los datos, mientras que el de un problema de ordenación será de nuevo aprender un orden, en este caso total, usando los datos de train (sin etiqueta) para ordenar los de test. El objetivo final de un problema de ranking multipartito es aprender un orden total de los datos usando para ello las etiquetas de los datos de entrenamiento, mientras que en regresión ordinal el enfoque no es encontrar un orden que describa los patrones, sino usar el orden presente en las etiquetas para tratar de asignar a las muestras las etiquetas más cercanas a las etiquetas reales de los datos. 

\subsection{Técnicas de Regresión Ordinal}
Las técnicas de regresión ordinal propuestas en la literatura se agrupan principalmente en tres: \textit{enfoques naïve, enfoques de descomposición binaria} y \textit{enfoques basados en límites}. 
\subsubsection{Enfoques naïve}
En ellos el modelo se obtiene usando otros algoritmos estándares de predicción, simplicando previamente el problema ordinal a un problema estándar. Se traducen sobre todo a problemas de regresión como NN,SVR,..., para lo que se transforman las etiquetas a valores reales \cite{Torra2006} o se reconstruye la variable clase a partir de las distancias entre clases \cite{Sanchez2013}, de clasificación nominal, por ejemplo SVM \cite{Vapnik2015}, donde simplemente se ignora el orden de las etiquetas o de clasificación sensitiva al coste, para diferentes errores de clasificación \cite{unknown}.  
\subsubsection{Enfoques de descomposición ordinal}
Estas técnicas se basan en descomponer las etiquetas ordinales en varias variables binarias, estimadas a partir de uno o varios modelos. Algunos de los algoritmos entrenan un modelo por cada subproblema (\textit{multiple model}) como el enfoque seguido en \cite{Hall}, que considera varios problemas de clasificación binaria independientemente, que luego combina en una única etiqueta, mientras que otros aprenden un único modelo para todos (\textit{multiple-output single model}). Por ejemplo el perceptrón ordinal en redes neuronales propuesto en \cite{cheng2008neural}, que codifica las clases de la misma forma que \cite{Hall} inicialmente.
\subsubsection{Enfoques basados en límites}
Asumen que en una variable continua no observada, llamada variable latente, reside la clase ordinal. Por tanto su objetivo es estimar una función textit{f} que prediga los valores de esa variable latente y un conjunto de límites o umbrales $b= (b_1,b_2,...b_n) \in \Re^n$ que representan intervalos en el rango de \textit{f} y que cumplan que $b_1 \le b_2 \le ... \le b_n$. Dentro de estos enfoques se incluyen los \textit{Cumulative Link Models} como POM \cite{mccullagh1980regression} que trata de extender la regresión logística binaria a regresión ordinal. También presentan este enfoque las variantes de SVM  SVOREX (Support Vector Ordinal Regression with
Explicit Constraints) y SVORIM (con restricciones implícitas) \cite{chu2007support}, métodos de aprendizaje discriminativo como KDLOR (Kernel Dis-
criminant Learning for Ordinal Regression) \cite{sun2010kernel}, clasificación binaria aumentada, ensembles (ORBoost) \cite{lin2006large} y procesos gaussianos (GPOR) \cite{chu2005gaussian}.
\section{El problema de la clasificación monotónica}
La clasificación monotónica es un caso especial de clasificación ordinal, donde las clases son ordinales y discretas, y existen ciertas restricciones de monotonicidad entre las características y sus clases, tal que para cualesquiera instancias $x, x'$ donde $x \le x' \Rightarrow f(x) \le f(x')$. Es decir, una instancia ($x'$) que sea mayor que otra ($x$) no puede tener una clase menor.
\section{Aplicaciones}