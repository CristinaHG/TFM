%!TEX root = ../dissertation.tex
\chapter{Resultados, conclusiones y vías futuras}
\label{conclusion}
\section{Resultados experimentales}
En esta sección se muestran los experimentos realizados con 10 datasets ordinales distintos, emplemando como medidas de evaluación el error absoluto medio y la tasa de error. Para realizar las experimentaciones de forma general se aplica la siguiente configuración no óptima de parámetros para los algoritmos:
\begin{itemize}
	\item SVM: coste =10,gamma=0.7
	\item POM: núcleo logístico
	\item KDLOR: núcleo RBF con parámetros 10, 0.001 y 1.
	\item WKNNOR: núcleo rectangular, cinco vecinos, distancia euclídea
	\item FSelector: k y $\beta$ =2, selecciona la mitad de características del dataset.
	\item ISelector: candidatos=0.01,colisiones=0.02, kedition=5
\end{itemize} 

Las especificaciones de los conjuntos de datos empleados se resumen en la siguiente tabla:

\begin{center}
	\begin{tabular}{ c c c c }
		 Dataset & Instancias & Atributos & Clases \\
		\hline	
		%ACC &	0.04458599 & 0.910828 & 0.8343949 & 0.7515924\\
		balance-scale &	625 & 4 & 3 \\
		winequality-red & 1599 & 11 & 6 \\
		SWD & 1000 & 10 & 4 \\
		contact-lenses & 24 & 6 & 3 \\
		toy & 300 & 2 & 5 \\
		ESL & 488 & 4 & 9 \\
		LEV & 1000 & 4 & 5 \\
		Automobile & 205 & 71 & 6\\
		Pasture & 36 & 25 & 3\\
		Squash-stored & 52 & 51 & 3 \\
		\hline  
	\end{tabular}
\end{center}

\subsection{Dataset balance-scale}
Resultados base de los algoritmos aplicados al dataset:\\
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR \\
	\hline	
%ACC &	0.04458599 & 0.910828 & 0.8343949 & 0.7515924\\
MAE &	1.840764 & 0.1019108 & 0.1656051 & 0.4076433\\
MZE &	0.955414 & 0.089172 & 0.1656051 & 0.2484076 \\
	\hline  
\end{tabular} 
\end{center}
\vspace{20pt}
Resultado de aplicar selección de características como paso previo, seleccionando 2/4 características: \newline

\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR \\
	\hline	
%	ACC &	0.4394904 & 0.7006369 & 0.6624204  & 0.5541401 \\
	MAE &	1.038217 & 0.5159236 & 0.477707  & 0.8089172 \\
	MZE &	0.5605096 & 0.2993631 & 0.3375796  & 0.4458599  \\
	\hline  
\end{tabular}
\end{center}

Resultados de aplicar se selección de instancias:

\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR \\
	\hline	
%	ACC &	0.1082803 & 0.8598726 & 0.566879  & 0.7324841 \\
	MAE &	1.700637 & 0.1910828 & 0.4522293  & 0.4458599 \\
	MZE &	0.8917197 & 0.1401274 & 0.433121  & 0.2675159  \\
	\hline  
\end{tabular}
\end{center}

Observamos en la tabla de resultados base que los algoritmos POM y KDLOR obtienen resultados en la línea de sus implementaciones matlab originales realizadas por P.A.Gutiérrez \cite{Gutiérrez2016}, resultando en un peor rendimiento de los algoritmos cuando se les aplica alguna de las dos técnicas de preprocesamiento implementadas.  WKNNOR con núcleo rectangular empeora su rendimiento ligeramente tras aplicarle selección de instancias, mientras que lo empeora significativamente más si su lugar, preprocesamos con selección de características. En cualquier caso, obtiene una tasa de error inicial no muy diferente a la obtenida en el algoritmo original que lo implementa \cite{duivesteijn2008nearest}, empleando un dataset de dimensiones muy similares. En cuanto a los resultados obtenidos por SVMOP, se alejan mucho de los obtenidos en \cite{Gutiérrez2016} para este dataset, lo que puede deberse a un error en la implementación o a que los parámetros coste y gamma de la SVM empleados no son los óptimos para este problema.

\subsection{Dataset Wine-quality red}
Resultados base de aplicar las técnicas de clasificación desarrolladas al dataset:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR\\
	\hline	
%	ACC &	0.005 & 0.5975 & 0.54  & 0.005 \\
	MAE &	2.6375 & 0.4425 & 0.51  & 2.635 \\
	MZE &	0.995 & 0.4025 & 0.46  & 0.995  \\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}
Aplicando selección de características (5/11):
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR \\
	\hline	
%	ACC &	0.005 & 0.52 & 0.3725  & 0.005 \\
	MAE &	2.5475 & 0.5525 & 0.95  & 2.635 \\
	MZE &	0.995 & 0.48 & 0.6275 & 0.995  \\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}
Aplicando selección de Instancias (1195 de 1199):\\
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR \\
	\hline	
%	ACC &	0.01 & 0.5975 & 0.5425  & 0.005 \\
	MAE &	2.6125 & 0.44 & 0.5075  & 2.635 \\
	MZE &	0.99 & 0.4025 & 0.4575 & 0.995  \\
	\hline  
\end{tabular}
\end{center}

De nuevo observamos el mal rendiemiento de la SVM ordinal, a diferencia del paper original \cite{waegeman2009ensemble} donde obtiene un error absoluto medio de entre 0.38-0.49 para datasets reales. El error absoluto medio y la tasa de error del resto de técnicas se mantiene similar a sus implementaciones originales para POM y KDLOR \cite{Gutiérrez2016} \cite{sun2010kernel}, mejorando en el caso de POM ligeramente el MZE (0.4025 frente a 0.40789) y KDLOR frente al caso base cuando se preprocesan los datos con el selector de instancias. El resto de algoritmos no se ven afectados por la selección de instancias, mientras que la selección de la mitad de características empeora el rendimiento en POM y KDLOR, aunque quizás no sería así eligiendo un número de características a seleccionar más óptimo. Por último el KNN ordinal obtiene una tasa de error muy superior a la que obtiene la implementación original con un dataset con igual número de atributos \cite{duivesteijn2008nearest}, si bien el dataset no era el mismo y en este caso el número de instancias era el doble (1199 frente a 546). Esto quizás podría paliarse con la utilización de otros parámetros en WKNNOR y otro tipo de kernel. 


\subsection{Dataset SWD}
Resultados base de la ejecución de los algoritmos de clasificación:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR \\
	\hline	
%	ACC &	0.024 & 0.536 & 0.544  & 0.16 \\
	MAE &	1.82 & 0.48 & 0.508  & 1.324 \\
	MZE &	0.976 & 0.464 & 0.456 & 0.84  \\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}
Aplicando selección de características como preprocesamiento:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR  \\
	\hline	
%	ACC &	0.02 & 0.512 & 0.496  & 0.18 \\
	MAE &	1.852 & 0.54 & 0.564  & 1.204 \\
	MZE &	0.98 & 0.488 & 0.504 & 0.82  \\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}
Aplicando selección de instancias como preprocesamiento:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR  \\
	\hline	
%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &	1.532 & 0.476 & 0.492  & 1.28 \\
	MZE &	0.88 & 0.464 & 0.448 & 0.812  \\
	\hline  
\end{tabular}
\end{center}

En este caso, los resultados base para KDLOR de MAE y MZE son mejores que los obtenidos en el experimento de \cite{Gutiérrez2016}, donde para el mismo dataset obtienen MAE y MZE igual a 0.5785 y 0.5137, respectivamente. Para POM son ligeramente inferiores (0.45 y 0.43 en el original), lo que puede deberse a una distinta función kernel empleada. WKNNOR no da buenos resultados, si bien no es comparable con los resultados del trabajo original \cite{duivesteijn2008nearest} dado que los autores no tienen resultados para datasets de más de 600 instancias. No obstante, este rendimiento puede mejorarse usando otros parámetros como cambiando el número de vecinos o el tipo de núcleo empleado. \newline
En cuanto a las técnicas de preprocesamiento empleadas, podemos decir que la selección de características solo mejora muy levemente a WKNN mientras que las otras no parecen beneficiarse, mientras que la selección de instancias sí parece beneficiar levemente a los cuatro algoritmos en este caso.

\subsection{Dataset Contact-lenses}
Resultados base de los algoritmos de clasificación implementados:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &	1.5 & - & 0.5  & 0.5 \\
	MZE &	0.8333333 & - & 0.5 & 0.3333333  \\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}
Resultados de aplicar selección de características previamente:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR  \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &      	1.5 & 0.5 & 0.8333333  & 0.5 \\
	MZE &	0.8333333 & 0.333333 & 0.8333333 & 0.3333333  \\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}
Resultados de aplicar selección de instancias previamente:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR  \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &      	1.5 & 1 & 0.5  & 0.5 \\
	MZE &	0.8333333 & 0.5 & 0.8333333 & 0.3333333  \\
	\hline  
\end{tabular}
\end{center}

El empleo de todos los atributos inicialmente hace que POM no converga, lo que se soluciona posteriormente con una selección de características. EL MAE base de KDLOR es ligeramente inferior al obtenido en la implementación en la que se basa ésta (0.5167) \cite{Gutiérrez2016},  sin embargo el valor de MZE es superior (0.5 frente a 0.33). Seguro que puede arreglarse usando otro núcleo y otros parámetros que no sean los de por defecto. Para este dataset parece que el rendimiento de WKNNOR es mejor, de hecho en la implementación original \cite{duivesteijn2008nearest} con un dataset de seis atributos como este y más características, obtienen una tasa de error de 51.8 \% frente a 33\% en este caso, si bien los problemas no son exactamente los mismos. En cuanto a los algoritmos de preprocesamiento, sólo se beneficia de la selección de características POM, mientras que ninguno de beneficia de la selección de instancias.

\subsection{Dataset Toy}
Resultados base de los clasificadores:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR + rectangular \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   2.86667  & 	0.88 &  0.1466667  & 1.933333 \\
	MZE &	1     &  0.6666667 & 0.1466667 & 0.8933333  \\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}
Aplicando selector de instancias:
\begin{center}
	
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR  \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   2.626667  & 	1.12 &  0.5466667 & 1.88  \\
	MZE &	0.9866667  &  0.64 & 0.4266667 & 0.88  \\
	\hline  
\end{tabular}
\end{center}

En este caso, al tratarse de un dataset con dos atributos no merecía la pena considerar una selección de características. Se observa en los resultados base que el único algoritmo que funciona bien inicialmente con este dataset es KDLOR, obteniendo resultados ligeramente superiores de MZE y MAE que en la implementación original de ORCA \cite{Gutiérrez2016} (0.107 y 0.114 respectivamente). Sin embargo, todos los algoritmos excepto este mejoran su rendimiento algo cuando se aplica selección de instancias previamente a la clasificación.

\subsection{Dataset ESL}
Resultados base de los algoritmos:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR  \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   4.204918  & 0.3606557 &	0.3934426 &  1.803279  \\
	MZE &	1         & 0.3278689 & 0.352459 & 0.8852459  \\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}
Resultados de aplicar selección de características:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR  \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   4.270492  & 0.5      & 0.5163934 &  1.803279  \\
	MZE &	1         & 0.442623 & 0.4590164 & 0.7622951  \\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}
Resultados de aplicar selección de instancias:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR  \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   3.45082  & 0.4262295 & 0.647541 &  2.52459  \\
	MZE &	0.9918033 & 0.3934426 & 0.5819672 & 0.9508197  \\
	\hline  
\end{tabular}
\end{center}

Los resultados base de KDLOR son similares a los del trabajo de referencia \cite{Gutiérrez2016}, al igual que los de POM. WKNNOR obtiene unas medidas de error muy altas para este problema de 9 clases, sin embargo en el tratajo de referencia \cite{duivesteijn2008nearest} no se ejemplifica el funcionamiento del algoritmo para un problema de 9 clases. La selección de características parece que beneficia a WKNNOR, mientras que la selección de instancias sólo beneficia sutilmente a SVM.


\subsection{Dataset LEV}
Resultados base de los algoritmos de clasificación:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR  \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   2.276  & 0.412 & 0.484 &  1.44  \\
	MZE &	0.98 & 0.376 & 0.42 & 0.784  \\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}
 Con selección de características:
 \begin{center}
 \begin{tabular}{ c c c c c }
 	& SVMOP & POM & KDLOR & WKNNOR  \\
 	\hline	
 	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
 	MAE &   2.212  & 0.584 & 0.7 &  1.412 \\
 	MZE &	0.972 & 0.512 & 0.572 & 0.804  \\
 	\hline  
 \end{tabular}
\end{center}
\vspace{20pt}
Aplicando selector de instancias:
\begin{center}
 \begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR  \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   2.236  & 0.44 & 0.48 &  1.396 \\
	MZE &	0.976 & 0.388 & 0.412 & 0.744  \\
	\hline  
\end{tabular}
\end{center}

Para POM y KDLOR de nuevo obtenemos resultados muy similares a los de el tabajo de referencia \cite{Gutiérrez2016}. A pesar de que el resultado de WKNNOR no es bueno inicialmente, no lo podemos comparar con el trabajo original \cite{duivesteijn2008nearest} dado que no muestran resultados para datasets con 1000 instancias. Aplicar el algoritmo de extracción de características a estos datos repercute en una mejora en WKNNOR, mientras que la selección de instancias sólo mejora ligeramente la SVM.
\subsection{Dataset Automobile}
Resultados base para los algoritmos de clasificiación:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   2.826923  & - & 1.019231 &  2.826923 \\
	MZE &	0.9807692 & - & 0.7307692 & 0.9807692  \\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}
Selector de características (35 de 71):
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR  \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   2.826923  & 1.134615 & 0.9807692 &  2.826923 \\
	MZE &	0.9807692 & 0.7692308 & 0.7115385 & 0.9807692  \\
	\hline  
\end{tabular}
\end{center}

En este caso, con los parámetros por defecto el selector de instancias sólo eliminaba una muestra, por lo que los resultados no fueron relevantes. Automobile es un dataset complicado de 71 atributos y 6 clases, por lo que los resultados no son prometedores para ninguno de los algoritmos. Sin embargo, sí que es útil experimentar con este dataset para comprobar que la selección de características puede ser crucial en problemas donde tenemos muchas, como este, pues a pesar de que hemos eliminado sólo la mitad por una prueba, claramente POM y KDLOR mejoran sus resultados gracias a ella.

\subsection{Dataset Pasture}
Resultados base de los clasificadores:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR + rectangular \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   1  & - & 0.6666667 &  1 \\
	MZE &	0.6666667 & - & 0.6666667 & 0.6666667  \\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}
Con Selección de características ( 7 de 25):
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   1  & 0.2222222 & 0.6666667 &  1 \\
	MZE &	0.6666667 & 0.2222222 & 0.6666667 & 0.6666667  \\
	\hline  
\end{tabular}
\end{center}

Puesto que el problema tiene sólo 27 instancias no se aplica selección de instancias. Inicialmente es necesario aplicar selección de características para aplicar POM, tras lo que obtenemos un MAE y MZE de 0.22, mucho mejor que la media de 0.58 y 0.50 respectivamente que obtiene el estudio de referencia \cite{Gutiérrez2016}. Sin embargo los valores obtenidos para KDLOR sí son muy inferiores a los del estudio de referencia (0.34 y 0.32 respectivamente), quizás por los parámetros y el tipo de núcleo usados. WKNN también proporciona peores resultados que los del trabajo original para dataset de dimensiones similares, pero pordría arreglarse probando con otros parámetros dado que WKNN es muy sensible a la configuración de parámetros.

\subsection{Dataset Squash-stored}
Resultados base del clasificador:
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   1.230769  & - & 0.5384615  &  0.7692308 \\
	MZE &	0.8461538 & - & 0.5384615 & 0.6153846 \\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}
Con selección de características (8 de 51):
\begin{center}
\begin{tabular}{ c c c c c }
	& SVMOP & POM & KDLOR & WKNNOR  \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   1.230769  & 0.3846154 & 0.5384615  &  0.7692308 \\
	MZE &	0.8461538 & 0.3076923 & 0.5384615 & 0.6153846 \\
	\hline  
\end{tabular}
\end{center}
Tras ejecutar selección de características, KDLOR obtiene una MZE=0.53, inferior al obtenido en el estudio de referencia (0.39), al igual que el MAE (0.53 frente a 0.374). POM sin embargo da unos resultados mucho mejores, con un MZE=0.3076 frente a 0.6179 y MAE= 0.3846 frente a 0.81 en el trabajo de referencia \cite{Gutiérrez2016}.
En este caso no se elimina ninguna instancia al realizar la selección de instancias, dada la configuración de parámetros por defecto.


\section*{Análisis de parámetros}
En esta sección se muestran los resultados de lanzar los algoritmos usando el dataset de referencia \textbf{Balance Dataset} probando con distintos tipos de núcleo para los algoritmos de clasificación:

KDLOR con distintos kernels:

\begin{center}
\begin{tabular}{ c c c c c  }
	& rbf & gauss & lineal & poly \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   0.1656051  & 0.1656051 & 0.2484076  &  0.2484076 \\
	MZE &	0.8461538 & 0.8461538 & 0.2484076 & 0.2484076 \\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}

POM con distintos kernels:
\begin{center}
\begin{tabular}{ c c c c c c }
	& logistic & probit & loglog & cloglog & cauchit \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   0.1019108  & 0.1210191 & 0.1592357  &  0.2101911 & 0.1082803\\
	MZE &	0.089172 & 0.1082803 & 0.1210191 & 0.1464968 &  0.0955414\\
	\hline  
\end{tabular}
\end{center}
\vspace{20pt}

WKNNOR con distintos kernels:

\begin{center}
\begin{tabular}{ c c c c c c c c }

	& rectangular & triangular & epanechnikov & biweight & triweight & cosine & inversion \\
	\hline	
	%	ACC &	      & 0.536 & 0.552  & 0.18 \\
	MAE &   0.4076433  & 0.388535 & 0.388535  &  0.3821656 & 0.3821656 & 0.388535 & 0.1019108 \\
	MZE &	0.2484076 & 0.2292994 & 0.2292994 & 0.2229299 & 0.2229299 & 0.2292994 & 0.089172  \\
	\hline  
\end{tabular}
\end{center}

\section{Conclusiones y vías futuras}
\subsection{Conclusiones}
POM y KDLOR dan unos resultados que, en general no se alejan del estudio de referencia \cite{Gutiérrez2016}, si bien como se puede ver en la sección anterior, puede variar mucho el resultado de estos cambiando simplemente el tipo de kernel que emplean. Aunque no se han empleado los mismos datasets que en la propuesta de KDLOR original \cite{duivesteijn2008nearest} se ha comprobado que, para datasets con dimensiones similares a veces da resultados cercanos a los originales y a veces no. Esto puede deberse simplemente a una configuración de parámetros, pues WKNN es un método muy sensible al número de vecinos empleado (en este caso, el de por defecto, 5), a la distancia empleada y al núcleo usado para calcular los pesos. De hecho, en la sección anterior podemos ver con el dataset \textbf{balance} como para WKNNOR simplemente el cambio del tipo de kernel puede resultar en una mejora del 16\% de la tasa de error. \newline
En cuanto a SVMOP, los resultados exigen una revisión del algoritmo, en términos de implementación y de parámetros. Sobre los algoritmos de preprocesamiento, no se puede concluir que sean o no útiles, ni tampoco que uno lo sea más que otro, pues a lo largo de la experimentación, ambos han servido para mejorar el rendimiento del clasificador en algunos casos y empeorarlo en otro. Podría decirse pues, que depende de los datos y de la naturaleza del problema su aplicación.

\subsection{Vías futuras}
Esta es la primera versión de OCAPIS y como tal, hay mucho que hacer aún sobre ella. Queda pendiente por tanto, mejorar la SVM para datos ordinales, implementar la selección de instancias de forma inmutable y funcional en lugar de iterativa, lo que tiene un impacto directo en la eficiencia y velocidad del paquete. También queda pendiente añadir más algoritmos a este paquete para clasificación ordinal, como SVOR en sus variantes SVOREX, SVORIM, ORBoost y una red neuronal. 
